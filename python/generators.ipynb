{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators #\n",
    "\n",
    "## Contents ##\n",
    "1. [From iterators to generators](#iterators_to_generators)\n",
    "2. [Why not lists?](#why_not_lists)\n",
    "3. [Introducing generators](#intro_gen)\n",
    "4. [Another example](#one_more_ex)\n",
    "5. [Some more examples](#more_examples)\n",
    "6. [Generator vs. ordinary function](#generator_vs_function)\n",
    "7. [Further reading](#further_reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='iterators_to_generators'></a>\n",
    "## From iterators to generators ##\n",
    "\n",
    "The theme of generators is intertwined with that of [Iterators](iterators.ipynb). Please read up first on the notebook about [Iterators](iterators.ipynb) before continuing to read this one.\n",
    "\n",
    "If you recall, an *iterator* is a container object implementing `__iter__` and `__next__`. It can be iterated over.\n",
    "\n",
    "A *generator* is a special iterator which can save the execution context. While an iterator is implemented as a class, a generator is written as a function which contains a `yield` statement.\n",
    "\n",
    "Often we can write easier code with the help of generators where we used iterators before.\n",
    "The last example in [Iterators](iterators.ipynb) showed that: We had an iterable class `Sentence` and the corresponding iterator class `SentenceIterator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.words = RE_WORD.findall(text)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return SentenceIterator(self.words)\n",
    "\n",
    "class SentenceIterator:\n",
    "    def __init__(self, words):\n",
    "        self.words = words\n",
    "        self.index = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            word = self.words[self.index]\n",
    "        except IndexError:\n",
    "            raise StopIteration()\n",
    "        self.index += 1\n",
    "        return word\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "at\n",
      "the\n",
      "beginning\n",
      "the\n",
      "King\n",
      "said\n",
      "very\n",
      "gravely\n",
      "and\n",
      "go\n",
      "on\n",
      "till\n",
      "you\n",
      "come\n",
      "to\n",
      "the\n",
      "end\n",
      "then\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "it = iter(Sentence('\"Begin at the beginning,\" the King said, very gravely, \"and go on till you come to the end: then stop.\"'))\n",
    "\n",
    "for word in it:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='why_not_lists'></a>\n",
    "## Why not lists? ##\n",
    "Quite fancy. But you could ask, why do we all need this? Why do we not simply work with lists? Let's look at just lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "go\n",
      "on\n",
      "till\n",
      "you\n",
      "come\n",
      "to\n",
      "the\n",
      "end\n",
      "then\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "class NonIterableSentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.words = RE_WORD.findall(text)\n",
    "\n",
    "    def get_words(self):\n",
    "        return self.words\n",
    "\n",
    "s = NonIterableSentence('\"and go on till you come to the end: then stop.\"')\n",
    "\n",
    "for word in s.get_words():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro_gen'></a>\n",
    "## Introducing generators ##\n",
    "\n",
    "One answer is, imagine we had a huge text with zillions of words. Then we don't necessarily want to store all of them in a list and in memory. On the other hand, with an iterator or generator (special iterator), we can lazily (on demand) generate our values and save memory space. Furthermore, we do not need to wait until all the elements have been generated before we can start using them.\n",
    "\n",
    "Now, *generators* are iterators that produce the values of the expressions passed to yield. Calling `next` on a generator will fetch the next item produced by yield while it remembered state from the last yield. When the function body is completed, StopIteration is raised.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "at\n",
      "the\n",
      "beginning\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.words = RE_WORD.findall(text)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for word in self.words:\n",
    "            yield word\n",
    "            \n",
    "s = Sentence('\"Begin at the beginning,\" the King said, very gravely, \"and go on till you come to the end: then stop.\"')\n",
    "it = iter(s)\n",
    "for i in range(0,5):\n",
    "    print(next(it))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite nice since it is very short. But we cheated, since we still initialize our words eagerly, not lazily. The function `re.findall`is eager: it returns the whole list of words at once. There is a lazy alternative: `re.finditer`: Using it, we do need no more list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "at\n",
      "the\n",
      "beginning\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import reprlib\n",
    "\n",
    "RE_WORD = re.compile('\\w+')\n",
    "\n",
    "class LazySentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for match in RE_WORD.finditer(self.text):\n",
    "            yield match.group()\n",
    "            \n",
    "s = LazySentence('\"Begin at the beginning,\" the King said, very gravely, \"and go on till you come to the end: then stop.\"')\n",
    "it = iter(s)\n",
    "for i in range(0,5):\n",
    "    print(next(it))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='one_more_ex'></a>\n",
    "## Another example ##\n",
    "\n",
    "Let's repeat with one more example:\n",
    "When we read data from a file we often do not need to read everything at once into memory. Let's first do it wrong: read the whole input into a list at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 94, 56, 15, 74, 32, 53, 79, 12, 99, 23, 44, 1, 78, 13, 54, 33, 50, 52, 57, 32, 63, 51, 94, 60, 33, 92, 82, 34, 95, 10, 66, 51, 12, 59, 93, 17, 52, 46, 51, 78, 50, 6, 70, 48, 75, 77, 51, 3, 70, 73, 18, 41, 10, 53, 50, 47, 97, 56, 86, 43, 6, 89, 5, 53, 63, 39, 84, 39, 75, 76, 46, 84, 92, 71, 69, 76, 80, 33, 45, 73, 37, 55, 39, 61, 77, 75, 40, 40, 19, 53, 43, 72, 92, 56, 15, 63, 27, 67, 76]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "data_file = 'random_numbers.txt'\n",
    "data = []\n",
    "\n",
    "def create_random_data():\n",
    "    with open(data_file, 'w') as file:\n",
    "        for _ in range(100):\n",
    "            file.write(str(random.randrange(1, 100))+'\\n')\n",
    "            \n",
    "def read_random_data():\n",
    "    with open(data_file, 'r') as file:\n",
    "        data = [int(line) for line in file.readlines()]\n",
    "    print(data)\n",
    "            \n",
    "create_random_data()\n",
    "read_random_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve, let us write our own iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "99\n",
      "73\n",
      "93\n",
      "10\n",
      "16\n",
      "27\n",
      "39\n",
      "40\n",
      "62\n",
      "49\n",
      "81\n",
      "75\n",
      "82\n",
      "74\n",
      "85\n",
      "28\n",
      "94\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class NumberReaderIterator:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.index = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        line = self.file.readline()\n",
    "        if line is None:\n",
    "            raise StopIteration()\n",
    "        self.index += 1\n",
    "        return int(line)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "data_file = 'random_numbers.txt'\n",
    "\n",
    "def create_random_data():\n",
    "    with open(data_file, 'w') as file:\n",
    "        for _ in range(100):\n",
    "            file.write(str(random.randrange(1, 100))+'\\n')\n",
    "            \n",
    "def read_random_data():\n",
    "    with open(data_file, 'r') as file:\n",
    "        it = NumberReaderIterator(file)\n",
    "        for _ in range(1, 20):\n",
    "            data = next(it)\n",
    "            print(data)\n",
    "            \n",
    "create_random_data()\n",
    "read_random_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we already know, we can simplify by writing an iterable whose `__iter__` returns a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "35\n",
      "33\n",
      "22\n",
      "3\n",
      "28\n",
      "89\n",
      "66\n",
      "96\n",
      "5\n",
      "44\n",
      "75\n",
      "30\n",
      "50\n",
      "41\n",
      "72\n",
      "72\n",
      "39\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class NumberReaderIterable:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                yield int(line)\n",
    "    \n",
    "data_file = 'random_numbers.txt'\n",
    "\n",
    "def create_random_data():\n",
    "    with open(data_file, 'w') as file:\n",
    "        for _ in range(100):\n",
    "            file.write(str(random.randrange(1, 100))+'\\n')\n",
    "            \n",
    "def read_random_data():\n",
    "    it = iter(NumberReaderIterable(data_file))\n",
    "    for _ in range(1, 20):\n",
    "        print(next(it))\n",
    "            \n",
    "create_random_data()\n",
    "read_random_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#more_examples\"></a>\n",
    "## More examples ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(directory):\n",
    "    \"\"\"A generator for all html pages inside a directory\"\"\"\n",
    "    for name in os.listdir(directory):\n",
    "        if name.endswith('.html'):\n",
    "            yield name[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#generator_vs_function\"></a>\n",
    "\n",
    "## Generator vs. ordinary function ##\n",
    "\n",
    "The difference between a generator function and an ordinary function (and the keypoint about the concept of generator) is that a generator function saves its state in between calls while a function forgets its state after return.\n",
    "\n",
    "Let's say we want to build a list of the first 10 factorials. How would we do it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628800\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "def factorial(n):\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "    \n",
    "print (factorial(10))\n",
    "print (factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first do it wrong again: write a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880]\n"
     ]
    }
   ],
   "source": [
    "def get_first_factorials(upper_limit):\n",
    "    values = []\n",
    "    for n in range(upper_limit):\n",
    "        values.append(factorial(n))\n",
    "    return values\n",
    "\n",
    "print(get_first_factorials(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_factorial_gen(upper_limit):\n",
    "    for n in range(upper_limit):\n",
    "        yield factorial(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "6\n",
      "24\n",
      "120\n",
      "720\n",
      "5040\n",
      "40320\n",
      "362880\n"
     ]
    }
   ],
   "source": [
    "for val in next_factorial_gen(10):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='further_reading'></a>\n",
    "## Further Reading ##\n",
    "- To repeat and deepen your understanding, you can read: [Comprehensions](comprehensions.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
